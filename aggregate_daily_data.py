#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å‹•ç”»å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥æ¬¡é›†ç´„ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

6æ™‚é–“ã”ã¨ã«åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ã€1æ—¥1ãƒ¬ã‚³ãƒ¼ãƒ‰ã«é›†ç´„ã—ã¾ã™ã€‚
å„æ—¥ã®æœ€çµ‚è¨˜éŒ²ï¼ˆãã®æ—¥ã®æœ€ã‚‚é…ã„æ™‚åˆ»ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’æ¡ç”¨ã—ã¾ã™ã€‚
"""

import json
import os
from datetime import datetime
from collections import defaultdict

def aggregate_daily_data(input_file, output_file):
    """
    ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ—¥æ¬¡é›†ç´„ã™ã‚‹
    
    Args:
        input_file: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆvideo_daily_history_*.jsonï¼‰
        output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆvideo_daily_aggregated_*.jsonï¼‰
    """
    print(f"ğŸ“Š å‡¦ç†é–‹å§‹: {input_file}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    if not os.path.exists(input_file):
        print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
        return
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    aggregated_data = {}
    total_videos = len(data)
    processed_videos = 0
    
    # å‹•ç”»ã”ã¨ã«å‡¦ç†
    for video_id, video_info in data.items():
        records = video_info.get('records', [])
        
        if not records:
            continue
        
        # æ—¥ä»˜ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        daily_records = defaultdict(list)
        
        for record in records:
            timestamp_str = record.get('timestamp', '')
            try:
                timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                date_key = timestamp.strftime('%Y-%m-%d')  # æ—¥ä»˜ã®ã¿
                daily_records[date_key].append({
                    'timestamp': timestamp,
                    'record': record
                })
            except ValueError:
                print(f"âš ï¸  ç„¡åŠ¹ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—: {timestamp_str}")
                continue
        
        # å„æ—¥ä»˜ã®æœ€çµ‚ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’é¸æŠ
        aggregated_records = []
        for date_key in sorted(daily_records.keys()):
            # ãã®æ—¥ã®æœ€ã‚‚é…ã„æ™‚åˆ»ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
            latest = max(daily_records[date_key], key=lambda x: x['timestamp'])
            aggregated_records.append(latest['record'])
        
        # é›†ç´„ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        aggregated_data[video_id] = {
            'ã‚¿ã‚¤ãƒˆãƒ«': video_info.get('ã‚¿ã‚¤ãƒˆãƒ«', ''),
            'å…¬é–‹æ—¥': video_info.get('å…¬é–‹æ—¥', ''),
            'type': video_info.get('type', 'Movie'),
            'records': aggregated_records
        }
        
        processed_videos += 1
        
        # é€²æ—è¡¨ç¤º
        if processed_videos % 10 == 0 or processed_videos == total_videos:
            print(f"  å‡¦ç†ä¸­... {processed_videos}/{total_videos} å‹•ç”»")
    
    # ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(aggregated_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å®Œäº†: {output_file}")
    print(f"   - å‡¦ç†ã—ãŸå‹•ç”»æ•°: {processed_videos}")
    
    # çµ±è¨ˆæƒ…å ±
    total_records_before = sum(len(v.get('records', [])) for v in data.values())
    total_records_after = sum(len(v.get('records', [])) for v in aggregated_data.values())
    print(f"   - ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records_before} â†’ {total_records_after}")
    print(f"   - å‰Šæ¸›ç‡: {(1 - total_records_after/total_records_before)*100:.1f}%")
    print()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ“… å‹•ç”»å±¥æ­´ãƒ‡ãƒ¼ã‚¿æ—¥æ¬¡é›†ç´„ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    print()
    
    # ã‚¿ãƒ¬ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—
    talents = []
    for file in os.listdir('.'):
        if file.startswith('video_daily_history_') and file.endswith('.json'):
            talent_name = file.replace('video_daily_history_', '').replace('.json', '')
            talents.append(talent_name)
    
    if not talents:
        print("âš ï¸  å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print("   video_daily_history_*.json ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        return
    
    print(f"ğŸ¯ å‡¦ç†å¯¾è±¡ã‚¿ãƒ¬ãƒ³ãƒˆ: {', '.join(talents)}")
    print()
    
    # å„ã‚¿ãƒ¬ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„
    for talent in talents:
        input_file = f'video_daily_history_{talent}.json'
        output_file = f'video_daily_aggregated_{talent}.json'
        aggregate_daily_data(input_file, output_file)
    
    print("=" * 60)
    print("ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("=" * 60)

if __name__ == '__main__':
    main()
